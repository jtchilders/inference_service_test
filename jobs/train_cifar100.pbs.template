#!/bin/bash
#PBS -N cifar100_train_${JOB_ID}
#PBS -l nodes=1
#PBS -l walltime=01:00:00
#PBS -l filesystems=home:flare
#PBS -A datascience
#PBS -q ${QUEUE}
#PBS -o ${OUTPUT_DIR}.stdout.txt
#PBS -e ${OUTPUT_DIR}.stderr.txt
#PBS -V

# CIFAR-100 Training Job Template for Aurora
# This template will be populated with hyperparameters by the job scheduler

set -e

# Load necessary modules for Aurora
# Aurora uses Intel oneAPI and Intel PyTorch
module load frameworks

# Set environment variables for Aurora
# export OMP_NUM_THREADS=1
# export OMP_PLACES=cores
# export OMP_PROC_BIND=close
# export I_MPI_PIN_DOMAIN=auto:compact
# export I_MPI_PIN_ORDER=compact

# Aurora GPU configuration
# Aurora uses Intel GPUs (Ponte Vecchio)
export ZE_AFFINITY_MASK=0

# Set environment variables
export PYTHONPATH="${PYTHONPATH}:${REPO_PATH}/src"

# Create output directory
mkdir -p ${OUTPUT_DIR}

# Log job start
echo "Job started at: $(date)"
echo "Job ID: ${JOB_ID}"
echo "Working directory: ${PBS_O_WORKDIR}"
echo "Repository path: ${REPO_PATH}"
echo "Output directory: ${OUTPUT_DIR}"
echo "Node: $(hostname)"
echo "GPU Info:"
sycl-ls 2>/dev/null || echo "SYCL devices not available"

# Hyperparameters (will be replaced by job scheduler)
# Model parameters
MODEL_TYPE="${MODEL_TYPE}"
HIDDEN_SIZE="${HIDDEN_SIZE}"
NUM_LAYERS="${NUM_LAYERS}"
DROPOUT_RATE="${DROPOUT_RATE}"

# Training parameters
LEARNING_RATE="${LEARNING_RATE}"
BATCH_SIZE="${BATCH_SIZE}"
NUM_EPOCHS="${NUM_EPOCHS}"
WEIGHT_DECAY="${WEIGHT_DECAY}"

# Data parameters
DATA_DIR="${DATA_DIR}"
NUM_WORKERS="${NUM_WORKERS}"

# Log hyperparameters
echo "=== Hyperparameters ==="
echo "Model Type: ${MODEL_TYPE}"
echo "Hidden Size: ${HIDDEN_SIZE}"
echo "Number of Layers: ${NUM_LAYERS}"
echo "Dropout Rate: ${DROPOUT_RATE}"
echo "Learning Rate: ${LEARNING_RATE}"
echo "Batch Size: ${BATCH_SIZE}"
echo "Number of Epochs: ${NUM_EPOCHS}"
echo "Weight Decay: ${WEIGHT_DECAY}"
echo "Data Directory: ${DATA_DIR}"
echo "Number of Workers: ${NUM_WORKERS}"
echo "======================"

# Activate virtual environment if specified
if [ ! -z "${VENV_PATH}" ]; then
   source ${VENV_PATH}/bin/activate
   echo "Activated virtual environment: ${VENV_PATH}"
fi

# Run the training script from the repository directory
cd ${REPO_PATH}

# Use Intel Python for PyTorch on Aurora
python src/training/train.py \
   --model_type ${MODEL_TYPE} \
   --hidden_size ${HIDDEN_SIZE} \
   --num_layers ${NUM_LAYERS} \
   --dropout_rate ${DROPOUT_RATE} \
   --learning_rate ${LEARNING_RATE} \
   --batch_size ${BATCH_SIZE} \
   --num_epochs ${NUM_EPOCHS} \
   --weight_decay ${WEIGHT_DECAY} \
   --data_dir ${DATA_DIR} \
   --num_workers ${NUM_WORKERS} \
   --output_dir ${OUTPUT_DIR} \
   --job_id ${JOB_ID}

# Log job completion
echo "Job completed at: $(date)"
echo "Exit code: $?"

# Copy results to a more permanent location if needed
if [ -f "${OUTPUT_DIR}/results.json" ]; then
   echo "Training results saved to: ${OUTPUT_DIR}/results.json"
fi 